{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a094586",
   "metadata": {},
   "source": [
    "# Binary Digit Classifier Using QNN with GUI input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da8589",
   "metadata": {},
   "source": [
    "### Project Desciption\n",
    "The Project first aims to briefly introduce Quantum Neural Networks and then build a Quantum Neural Network (QNN) to classify handwritten 0 and 1 (using MNIST handwritten data). And then, we'll make a Graphical User Interface (GUI) using which the user can draw a digit. And afterward, we'll integrate the GUI with the QNN above. And then, we'll classify whether the user has made 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f6ea11",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda8bd7",
   "metadata": {},
   "source": [
    "- https://arxiv.org/pdf/1802.06002.pdf\n",
    "- https://www.tensorflow.org/quantum/tutorials/mnist\n",
    "- https://docs.python.org/3/library/tk.html\n",
    "- https://tkdocs.com/tutorial/index.html\n",
    "- https://pennylane.ai/qml/glossary/quantum_neural_network.html\n",
    "- https://en.wikipedia.org/wiki/Quantum_neural_network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d474c59",
   "metadata": {},
   "source": [
    "### What is Quantum Neural Networks ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6a111",
   "metadata": {},
   "source": [
    "A quantum neural network (QNN) is a machine learning model or algorithm that combines concepts from quantum computing and artifical neural networks.Quantum Neural Network extends the key features and structures of Neural Networks to quantum systems.\n",
    "Most Quantum neural networks are developed as feed-forward networks. Similar to their classical counterparts, this structure intakes input from one layer of qubits, and passes that input onto another layer of qubits. This layer of qubits evaluates this information and passes on the output to the next layer. Eventually the path leads to the final layer of qubits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2eb028",
   "metadata": {},
   "source": [
    "<img src="QNN.png">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f53754",
   "metadata": {},
   "source": [
    "Fig1: Illustration of QNN with the input |ψ>, the parameter θ and linear entanglement structure.[image_source](https://arxiv.org/pdf/2108.01468.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff124d10",
   "metadata": {},
   "source": [
    "Now let's start building the QNN Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4281bd9a",
   "metadata": {},
   "source": [
    "### Libraries Used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6a1cb",
   "metadata": {},
   "source": [
    "- **cirq**\n",
    "- **tensorflow** \n",
    "- **tensorflow_quantum**\n",
    "- **numpy**\n",
    "- **sympy**\n",
    "- **seaborn**\n",
    "- **matplotlib**\n",
    "- **tkinter**\n",
    "- **opencv**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b0544",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7867198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615d718",
   "metadata": {},
   "source": [
    "### Flowchart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb947b",
   "metadata": {},
   "source": [
    "![alt text](Flowchart.png \"Flowchart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a34b9e",
   "metadata": {},
   "source": [
    "### Index\n",
    "\n",
    "#### 1. Data Loading, Filtering and Encoding\n",
    "#####    &emsp;1.1 Data Loading\n",
    "#####    &emsp;1.2 Data Filtering\n",
    "#####    &emsp;1.3 Downscaling Images to 4x4 \n",
    "#####    &emsp;1.4 Removing Contradictory Examples\n",
    "#####    &emsp;1.5 Encoding the data as quantum Circuits\n",
    "#### 2. Building QNN (Quantum Neural Network)\n",
    "#####    &emsp;2.1 Building the model Circuit\n",
    "#####    &emsp;2.2 Wrapping the model_circuit in a tfq.keras model\n",
    "#####    &emsp;2.3 Training and Evaluating QNN\n",
    "#### 3. Saving QNN Model\n",
    "#### 4. Making GUI using tkinter\n",
    "#### 5. Integrating GUI with QNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429baf09",
   "metadata": {},
   "source": [
    "#### 1. Data Loading, Filtering and Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e490dd",
   "metadata": {},
   "source": [
    "##### 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba860fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples before filtering: 60000\n",
      "Number of testing examples before filtering: 10000\n"
     ]
    }
   ],
   "source": [
    "#Loading MNIST Dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescaling the images to [0.0,1.0] Range.\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "print(\"Number of training examples before filtering:\", len(x_train))\n",
    "print(\"Number of testing examples before filtering:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbce7ae",
   "metadata": {},
   "source": [
    "##### 1.2 Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24534e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples after filtering: 12665\n",
      "Number of testing examples after filtering: 2115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Defining Function to filter dataset to keep just 0's and 1's.\n",
    "def filter_01(x, y):\n",
    "    keep = (y == 0) | (y == 1)\n",
    "    x, y = x[keep], y[keep]\n",
    "    y = y == 0\n",
    "    return x,y\n",
    "\n",
    "# Filtering using Above Function to keep 0's and 1's\n",
    "x_train, y_train = filter_01(x_train, y_train)\n",
    "x_test, y_test = filter_01(x_test, y_test)\n",
    "\n",
    "print(\"Number of training examples after filtering:\", len(x_train))\n",
    "print(\"Number of testing examples after filtering:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f839bd79",
   "metadata": {},
   "source": [
    "##### 1.3 Downscaling Images to 4x4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4decc52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscaled_x_train = tf.image.resize(x_train, (4,4)).numpy()\n",
    "downscaled_x_test = tf.image.resize(x_test, (4,4)).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "028e063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Downscaling:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x23a14473860>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying the first training image before and after downscaling\n",
    "print(\"Before Downscaling:\")\n",
    "plt.imshow(x_train[0,:,:,0], vmin=0, vmax=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f94e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Downscaling:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x23a1473aac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"After Downscaling:\")\n",
    "plt.imshow(downscaled_x_train[0,:,:,0], vmin=0, vmax=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0c7f1",
   "metadata": {},
   "source": [
    "##### 1.4 Removing Contradictory Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa405d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 7100\n",
      "Number of unique 0s:  4924\n",
      "Number of unique 1s:  2068\n",
      "Number of unique contradicting labels (both 0 and 1):  108\n",
      "\n",
      "Initial number of images:  12665\n",
      "Remaining non-contradicting unique images:  6992\n"
     ]
    }
   ],
   "source": [
    "# Defining Function to remove conradictory Examples.\n",
    "def remove_contradicting(xs, ys):\n",
    "    mapping = collections.defaultdict(set)\n",
    "    orig_x = {}\n",
    "    # Determine the set of labels for each unique image:\n",
    "    for x,y in zip(xs,ys):\n",
    "       orig_x[tuple(x.flatten())] = x\n",
    "       mapping[tuple(x.flatten())].add(y)\n",
    "    \n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    for flatten_x in mapping:\n",
    "      x = orig_x[flatten_x]\n",
    "      labels = mapping[flatten_x]\n",
    "      if len(labels) == 1:\n",
    "          new_x.append(x)\n",
    "          new_y.append(next(iter(labels)))\n",
    "      else:\n",
    "          # Throw out images that match more than one label.\n",
    "          pass\n",
    "    \n",
    "    num_uniq_0 = sum(1 for value in mapping.values() if len(value) == 1 and True in value)\n",
    "    num_uniq_1 = sum(1 for value in mapping.values() if len(value) == 1 and False in value)\n",
    "    num_uniq_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
    "\n",
    "    print(\"Number of unique images:\", len(mapping.values()))\n",
    "    print(\"Number of unique 0s: \", num_uniq_0)\n",
    "    print(\"Number of unique 1s: \", num_uniq_1)\n",
    "    print(\"Number of unique contradicting labels (both 0 and 1): \", num_uniq_both)\n",
    "    print()\n",
    "    print(\"Initial number of images: \", len(xs))\n",
    "    print(\"Remaining non-contradicting unique images: \", len(new_x))\n",
    "    \n",
    "    return np.array(new_x), np.array(new_y)\n",
    "\n",
    "x_train_nocon, y_train_nocon = remove_contradicting(downscaled_x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707dda1",
   "metadata": {},
   "source": [
    "##### 1.5 Encoding the data as quantum Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25198410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 126\n",
      "Number of unique 0s:  88\n",
      "Number of unique 1s:  5\n",
      "Number of unique contradicting labels (both 0 and 1):  33\n",
      "\n",
      "Initial number of images:  6992\n",
      "Remaining non-contradicting unique images:  93\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
    "x_test_bin = np.array(downscaled_x_test > THRESHOLD, dtype=np.float32)\n",
    "\n",
    "_ = remove_contradicting(x_train_bin, y_train_nocon)\n",
    "\n",
    "# Defining Function to convert images to circuit\n",
    "def convert_to_circuit(image):\n",
    "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
    "    values = np.ndarray.flatten(image)\n",
    "    qubits = cirq.GridQubit.rect(4, 4)\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(values):\n",
    "        if value:\n",
    "            circuit.append(cirq.X(qubits[i]))\n",
    "    return circuit\n",
    "\n",
    "\n",
    "x_train_circ = [convert_to_circuit(x) for x in x_train_bin]\n",
    "x_test_circ = [convert_to_circuit(x) for x in x_test_bin]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e84c6b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit for the first train example\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"164.49359375\" height=\"50.0\"><line x1=\"32.246796875\" x2=\"134.49359375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(1, 1): </text><rect x=\"74.49359375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"94.49359375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x23a1322ec88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Circuit for the first train example\")\n",
    "SVGCircuit(x_train_circ[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba52af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Cirq circuits to tensors for TensorflowQuantum\n",
    "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
    "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21df577",
   "metadata": {},
   "source": [
    "#### 2. Building QNN (Quantum Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ef8b6",
   "metadata": {},
   "source": [
    "##### 2.1 Building the model Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858962ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitLayerBuilder():\n",
    "    def __init__(self, data_qubits, readout):\n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "    \n",
    "    def add_layer(self, circuit, gate, prefix):\n",
    "        for i, qubit in enumerate(self.data_qubits):\n",
    "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
    "            circuit.append(gate(qubit, self.readout)**symbol)\n",
    "            \n",
    "def create_quantum_model():\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)\n",
    "\n",
    "model_circuit, model_readout = create_quantum_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c999a23",
   "metadata": {},
   "source": [
    "##### 2.2 Wrapping the model_circuit in a tfq.keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c265785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pqc (PQC)                    (None, 1)                 32        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build the Keras model.\n",
    "model = tf.keras.Sequential([\n",
    "    # The input is the data-circuit, encoded as a tf.string\n",
    "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
    "    tfq.layers.PQC(model_circuit, model_readout),\n",
    "])\n",
    "\n",
    "y_train_hinge = 2.0*y_train_nocon-1.0\n",
    "y_test_hinge = 2.0*y_test-1.0\n",
    "\n",
    "def hinge_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true) > 0.0\n",
    "    y_pred = tf.squeeze(y_pred) > 0.0\n",
    "    result = tf.cast(y_true == y_pred, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(result)\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.Hinge(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[hinge_accuracy])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3f49f",
   "metadata": {},
   "source": [
    "##### 2.3 Training and Evaluating QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1baa09fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6992 samples, validate on 2115 samples\n",
      "Epoch 1/4\n",
      "6992/6992 [==============================] - 1199s 172ms/sample - loss: 0.8508 - hinge_accuracy: 0.6936 - val_loss: 0.5303 - val_hinge_accuracy: 0.8577\n",
      "Epoch 2/4\n",
      "6992/6992 [==============================] - 1206s 173ms/sample - loss: 0.5344 - hinge_accuracy: 0.7653 - val_loss: 0.5292 - val_hinge_accuracy: 0.8806\n",
      "Epoch 3/4\n",
      "6992/6992 [==============================] - 1205s 172ms/sample - loss: 0.4670 - hinge_accuracy: 0.8172 - val_loss: 0.5940 - val_hinge_accuracy: 0.6244\n",
      "Epoch 4/4\n",
      "6992/6992 [==============================] - 1522s 218ms/sample - loss: 0.4504 - hinge_accuracy: 0.8457 - val_loss: 0.5614 - val_hinge_accuracy: 0.9058\n",
      "2115/2115 [==============================] - 25s 12ms/sample - loss: 0.5614 - hinge_accuracy: 0.9058\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 4\n",
    "BATCH_SIZE = 32\n",
    "NUM_EXAMPLES = len(x_train_tfcirc)\n",
    "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
    "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]\n",
    "\n",
    "qnn_history = model.fit(\n",
    "      x_train_tfcirc_sub, y_train_hinge_sub,\n",
    "      batch_size=32,\n",
    "      epochs=EPOCHS,\n",
    "      verbose=1,\n",
    "      validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f2dcf",
   "metadata": {},
   "source": [
    "#### 3. Saving QNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f302ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('01_MNIST.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ea316",
   "metadata": {},
   "source": [
    "#### 4. Making GUI using tkinter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d55cf06",
   "metadata": {},
   "source": [
    "####  [Will be updated]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d39d5b",
   "metadata": {},
   "source": [
    "#### 5. Integrating GUI with QNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd5a22",
   "metadata": {},
   "source": [
    "####  [Will be updated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe03f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
